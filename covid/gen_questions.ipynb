{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d3cfb80-eae7-4707-9c22-3290ba635225",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b275135",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = \"Data/\"\n",
    "name = \"COVID Super Expert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe117eb-82dc-44cb-b23e-1bc80d4394b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs = pd.read_json(f\"{dir_root}/covid_subset_paragraphs.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c18868f-127b-4f34-9a4c-9729ea0162e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"voidful/context-only-question-generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3cbac0e1-3a9a-449f-b998-3ac123f8ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"voidful/context-only-question-generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "118fc519-540d-43a0-88e9-c46502a9c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(number_of_questions, text, model, tokenizer, device):\n",
    "    inputs = tokenizer(\n",
    "        text, \n",
    "        max_length=256, \n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    questions = []\n",
    "    for step in range(0,number_of_questions):\n",
    "        summary_ids = model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            num_beams=2, \n",
    "            min_length=0, \n",
    "            max_length=36, \n",
    "            do_sample=True, \n",
    "            num_return_sequences=1, \n",
    "            no_repeat_ngram_size=3, \n",
    "            temperature=0.8)\n",
    "\n",
    "        question = tokenizer.batch_decode(\n",
    "            summary_ids, \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=False)\n",
    "        \n",
    "        questions.append(question[0])\n",
    "\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa74862f-53b3-4c19-b752-a305bade286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"Plant organs of high starch or sugar content have long since served for manufacturing alcohol, which was also used as fuel, \n",
    "but larger volumes were first consumed before and during World War II. Subsequently, the cheap petrol distilled from oil crowded out the expensive alcohol, \n",
    "but the years of oil crisis and the lead-contamination of environment concentrated attention upon bioalcohol or bioethanol as a fuel.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92ec5a47-e4e9-4db8-a664-aaa5f67f4226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['How many years did the oil crisis last?',\n",
       " 'What was the main source of fuel?',\n",
       " 'What was used as fuel before World War II?',\n",
       " 'How many years after the oil crisis was petroleum first distilled?',\n",
       " 'What was primarily used as fuel?']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\n",
    "    number_of_questions = 5,\n",
    "    text = test_text,\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    device = \"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "02184cc6-72be-4f98-ac22-bdeb4ae6e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 18239/18239 [2:39:58<00:00,  1.90it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(0, len(df_paragraphs[\"paragraph\"].values)))\n",
    "qaa = []\n",
    "\n",
    "for i in pbar:    \n",
    "    text = df_paragraphs[\"paragraph\"].values[i].strip()\n",
    "    \n",
    "    questions = generate(\n",
    "        number_of_questions = 5,\n",
    "        text = text,\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        device = \"auto\"\n",
    "    )\n",
    "\n",
    "    for question in questions:\n",
    "        qaa.append({\n",
    "            \"question\" : question.strip(), \n",
    "            \"name\" : name, \n",
    "            \"answare\" : text,\n",
    "            \"title\" : df_paragraphs[\"title\"].values[i],\n",
    "            \"cord_uid\" : df_paragraphs[\"cord_uid\"].values[i], \n",
    "            \"arxiv_id\" : df_paragraphs[\"arxiv_id\"].values[i],\n",
    "            \"pmc_json_files\" : df_paragraphs[\"arxiv_id\"].values[i]})\n",
    "\n",
    "print(len(qaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d271d08c-59c4-410d-b2f8-ae31d487e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_qaa = f\"{dir_root}qaa.json\"\n",
    "output_qaa_duplicated = f\"{dir_root}qaa_duplicated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e54eb639-bfeb-4643-a67e-deda47a5c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qaa_duplicated = pd.DataFrame(qaa)\n",
    "df_qaa_duplicated = df_qaa_duplicated.drop_duplicates()\n",
    "df_qaa_duplicated.to_json(output_qaa_duplicated + \".json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3336652-dc25-4f68-8d00-2456d31401d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58290 entries, 0 to 58289\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   question        58290 non-null  object \n",
      " 1   name            58290 non-null  object \n",
      " 2   answare         58290 non-null  object \n",
      " 3   title           58290 non-null  object \n",
      " 4   cord_uid        58290 non-null  object \n",
      " 5   arxiv_id        58290 non-null  float64\n",
      " 6   pmc_json_files  58290 non-null  float64\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_qaa_duplicated = pd.read_json(output_qaa_duplicated + \".json\",orient=\"records\")\n",
    "df_qaa_duplicated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61b7fecf-1462-4999-8c96-7e7ed3855c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>name</th>\n",
       "      <th>answare</th>\n",
       "      <th>title</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pmc_json_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which group had a lower median age, those with...</td>\n",
       "      <td>COVID Super Expert</td>\n",
       "      <td>A prevalent symptom of Parkinson’s disease (PD...</td>\n",
       "      <td>On the emergence of a power law in the distrib...</td>\n",
       "      <td>hx8bnrsi</td>\n",
       "      <td>2004.12772</td>\n",
       "      <td>2004.12772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many people had no PD?</td>\n",
       "      <td>COVID Super Expert</td>\n",
       "      <td>A prevalent symptom of Parkinson’s disease (PD...</td>\n",
       "      <td>On the emergence of a power law in the distrib...</td>\n",
       "      <td>hx8bnrsi</td>\n",
       "      <td>2004.12772</td>\n",
       "      <td>2004.12772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many more people had PD than had no PD?</td>\n",
       "      <td>COVID Super Expert</td>\n",
       "      <td>A prevalent symptom of Parkinson’s disease (PD...</td>\n",
       "      <td>On the emergence of a power law in the distrib...</td>\n",
       "      <td>hx8bnrsi</td>\n",
       "      <td>2004.12772</td>\n",
       "      <td>2004.12772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many total videos were in the dataset?</td>\n",
       "      <td>COVID Super Expert</td>\n",
       "      <td>The dataset consists of 1812 videos from 604 (...</td>\n",
       "      <td>On the emergence of a power law in the distrib...</td>\n",
       "      <td>hx8bnrsi</td>\n",
       "      <td>2004.12772</td>\n",
       "      <td>2004.12772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many total videos are in the dataset?</td>\n",
       "      <td>COVID Super Expert</td>\n",
       "      <td>The dataset consists of 1812 videos from 604 (...</td>\n",
       "      <td>On the emergence of a power law in the distrib...</td>\n",
       "      <td>hx8bnrsi</td>\n",
       "      <td>2004.12772</td>\n",
       "      <td>2004.12772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                name  \\\n",
       "0  Which group had a lower median age, those with...  COVID Super Expert   \n",
       "1                         How many people had no PD?  COVID Super Expert   \n",
       "2        How many more people had PD than had no PD?  COVID Super Expert   \n",
       "3         How many total videos were in the dataset?  COVID Super Expert   \n",
       "4          How many total videos are in the dataset?  COVID Super Expert   \n",
       "\n",
       "                                             answare  \\\n",
       "0  A prevalent symptom of Parkinson’s disease (PD...   \n",
       "1  A prevalent symptom of Parkinson’s disease (PD...   \n",
       "2  A prevalent symptom of Parkinson’s disease (PD...   \n",
       "3  The dataset consists of 1812 videos from 604 (...   \n",
       "4  The dataset consists of 1812 videos from 604 (...   \n",
       "\n",
       "                                               title  cord_uid    arxiv_id  \\\n",
       "0  On the emergence of a power law in the distrib...  hx8bnrsi  2004.12772   \n",
       "1  On the emergence of a power law in the distrib...  hx8bnrsi  2004.12772   \n",
       "2  On the emergence of a power law in the distrib...  hx8bnrsi  2004.12772   \n",
       "3  On the emergence of a power law in the distrib...  hx8bnrsi  2004.12772   \n",
       "4  On the emergence of a power law in the distrib...  hx8bnrsi  2004.12772   \n",
       "\n",
       "   pmc_json_files  \n",
       "0      2004.12772  \n",
       "1      2004.12772  \n",
       "2      2004.12772  \n",
       "3      2004.12772  \n",
       "4      2004.12772  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qaa_duplicated = pd.read_json(output_qaa_duplicated + \".json\",orient=\"records\")\n",
    "df_qaa_duplicated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ddd5ccc8-96e1-4b6b-89c1-c61b4d66f810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 58290/58290 [00:01<00:00, 50665.08it/s]\n"
     ]
    }
   ],
   "source": [
    "restruct = {}\n",
    "for i in tqdm(range(0,len(df_qaa_duplicated))):\n",
    "    if df_qaa_duplicated[\"answare\"].values[i] in restruct:\n",
    "        restruct[df_qaa_duplicated[\"answare\"].values[i]][\"questions\"].append(df_qaa_duplicated[\"question\"].values[i])\n",
    "    else:\n",
    "        restruct[df_qaa_duplicated[\"answare\"].values[i]] = {\n",
    "            \"questions\" : [df_qaa_duplicated[\"question\"].values[i]],\n",
    "            \"name\" : df_qaa_duplicated[\"name\"].values[i],\n",
    "            \"answare\" : df_qaa_duplicated[\"answare\"].values[i],\n",
    "            \"title\" : df_qaa_duplicated[\"title\"].values[i],\n",
    "            \"cord_uid\" : df_qaa_duplicated[\"cord_uid\"].values[i],\n",
    "            \"pmc_json_files\" : df_qaa_duplicated[\"pmc_json_files\"].values[i],\n",
    "            \"arxiv_id\" : str(df_qaa_duplicated[\"arxiv_id\"].values[i])[0:10]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "421a36d0-d958-4df8-b07d-93a62bb5f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 18004/18004 [00:00<00:00, 2085625.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'questions': ['Which group had a lower median age, those with PD or those without PD?',\n",
       "  'How many people had no PD?',\n",
       "  'How many more people had PD than had no PD?'],\n",
       " 'name': 'COVID Super Expert',\n",
       " 'answare': 'A prevalent symptom of Parkinson’s disease (PD) is hypomimia — reduced facial expressions.In this paper, we present a method for diagnosing PD that utilizes the study of micro-expressions.We analyzed the facial action units (AU) from 1812 videos of 604 individuals (61 with PD and 543 without PD, with a mean age 63.9 y/o, sd.7.8) collected online through a web-based tool (www.parktest.net).In these videos, participants were asked to make three facial expressions (a smiling, disgusted, and surprised face) followed by a neutral face.Using techniques from computer vision and machine learning, we objectively measured the variance of the facial muscle movements and used it to distinguish between individuals with and without PD.The prediction accuracy using the facial micro-expressions was comparable to methodologies that utilize motor symptoms.',\n",
       " 'title': 'On the emergence of a power law in the distribution of COVID-19 cases',\n",
       " 'cord_uid': 'hx8bnrsi',\n",
       " 'pmc_json_files': 2004.12772,\n",
       " 'arxiv_id': '2004.12772'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restruct = [restruct[key] for key in tqdm(restruct.keys())]\n",
    "restruct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c182ddd-f2de-488a-a46c-f03bab4fe376",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_qaa, 'w') as f:\n",
    "    json.dump(restruct, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SuperExpertRAG]",
   "language": "python",
   "name": "conda-env-SuperExpertRAG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
